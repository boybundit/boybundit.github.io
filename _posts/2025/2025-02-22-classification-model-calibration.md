---
layout: post
title: Classification Model Calibration 
slug: classification-model-calibration 
date: 2025-02-22 14:40:00 +0700
image: /assets/images/2025-02-22-classification-model-calibration/og-image.webp
---

‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Å‡∏£‡∏¥‡πà‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏ß‡πà‡∏≤ machine learning ‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ 2 ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏£‡∏Å‡∏Ñ‡∏∑‡∏≠ regression ‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏£‡∏≤‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏à‡∏£‡∏¥‡∏á‡∏≠‡∏≠‡∏Å‡∏°‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô ‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥, ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏´‡∏∏‡πâ‡∏ô ‡∏Å‡∏±‡∏ö‡∏≠‡∏µ‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏∑‡∏≠ classification ‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏£‡∏≤‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ß‡πà‡∏≤‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÑ‡∏´‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏π‡∏õ‡∏ô‡∏µ‡πâ‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏°‡∏ß, ‡∏û‡∏£‡∏∏‡πà‡∏á‡∏ô‡∏µ‡πâ‡∏ù‡∏ô‡∏ô‡πà‡∏≤‡∏à‡∏∞‡∏ï‡∏Å

‡πÅ‡∏ï‡πà‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏≠‡∏≤‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á ‡∏ö‡∏≤‡∏á‡∏ó‡∏µ‡πÄ‡∏£‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡∏≤‡∏Å‡∏£‡∏π‡πâ‡πÅ‡∏Ñ‡πà‡∏ß‡πà‡∏≤‡∏°‡∏±‡∏ô‡∏ô‡πà‡∏≤‡∏à‡∏∞‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÑ‡∏´‡∏ô ‡πÅ‡∏ï‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡∏£‡∏π‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏î‡πâ‡∏ß‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô  ‡∏Ñ‡∏ô‡πÑ‡∏Ç‡πâ‡∏Ñ‡∏ô‡∏ô‡∏µ‡πâ‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏∞‡πÄ‡∏£‡πá‡∏á 60% ‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏≠‡∏≤‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡∏´‡∏°‡∏≠‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÉ‡∏´‡πâ‡πÑ‡∏õ‡∏ï‡∏£‡∏ß‡∏à‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏∑‡πà‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à

‡∏ó‡∏µ‡∏ô‡∏µ‡πâ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á classification model ‡∏õ‡∏Å‡∏ï‡∏¥‡∏°‡∏±‡∏ô‡∏à‡∏∞‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏û‡πà‡∏ô probability ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡πÜ ‡πÄ‡∏ä‡πà‡∏ô ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ [decision tree](https://en.wikipedia.org/wiki/Decision_tree) ‡∏´‡∏£‡∏∑‡∏≠ [SVM](https://en.wikipedia.org/wiki/Support_vector_machine) ‡∏ï‡∏≤‡∏°‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á model ‡∏°‡∏±‡∏ô‡∏ö‡∏≠‡∏Å‡πÑ‡∏î‡πâ‡πÅ‡∏Ñ‡πà‡∏ß‡πà‡∏≤‡∏≠‡∏¢‡∏π‡πà class ‡πÑ‡∏´‡∏ô

‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ [ANN](https://en.wikipedia.org/wiki/Neural_network_(machine_learning)) ‡∏õ‡∏Å‡∏ï‡∏¥‡πÉ‡∏ô output layer ‡πÄ‡∏Ñ‡πâ‡∏≤‡∏à‡∏∞‡πÉ‡∏™‡πà sigmoid activation function ‡πÑ‡∏ß‡πâ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏°‡∏±‡∏ô‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô probability ‡πÅ‡∏ï‡πà‡πÉ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏£‡∏¥‡∏á ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏°‡∏±‡∏ô‡∏°‡∏±‡∏Å‡∏à‡∏∞ over-confident ‡πÑ‡∏°‡πà‡πÉ‡∏Å‡∏•‡πâ 0 ‡∏Å‡πá‡πÉ‡∏Å‡∏•‡πâ 1 ‡πÑ‡∏õ‡πÄ‡∏•‡∏¢ ‡∏ï‡∏≤‡∏°‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á model ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏°‡∏ß‡πà‡∏≤‡∏°‡∏±‡∏ô‡∏ó‡∏≥‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏° ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏™‡∏≠‡∏ô‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡πÅ‡∏°‡∏ß ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏î‡∏π‡∏£‡∏π‡∏õ‡πÅ‡∏°‡∏ß‡πÄ‡∏¢‡∏≠‡∏∞‡πÜ ‡πÅ‡∏•‡πâ‡∏ß‡∏û‡∏≠‡πÄ‡∏≠‡∏≤‡∏£‡∏π‡∏õ‡∏´‡∏°‡∏≤‡∏°‡∏≤‡πÉ‡∏´‡πâ‡∏î‡∏π ‡πÄ‡∏£‡∏≤‡∏Å‡πá‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡πÅ‡∏´‡∏•‡∏∞‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÅ‡∏°‡∏ß ‡πÅ‡∏ï‡πà‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡πÅ‡∏°‡∏ß‡∏Å‡∏µ‡πà percent ‡∏°‡∏±‡∏ô‡∏Å‡πá‡∏ï‡∏≠‡∏ö‡∏¢‡∏≤‡∏Å‡∏õ‡πà‡∏∞‡∏•‡πà‡∏∞ 555+ üòÇ

‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡πÉ‡∏´‡πâ classification model ‡∏û‡πà‡∏ô probability ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÉ‡∏´‡πâ ‡∏´‡∏£‡∏∑‡∏≠‡∏ñ‡πâ‡∏≤‡∏û‡πà‡∏ô‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡πá‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô ‡πÄ‡∏£‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ calibration ‡πÇ‡∏î‡∏¢‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏∑‡∏≠ predicted probability ‡∏Ñ‡∏ß‡∏£‡∏™‡∏∞‡∏ó‡πâ‡∏≠‡∏ô‡∏ñ‡∏∂‡∏á‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ô‡∏±‡πâ‡∏ô‡πÜ ‡πÄ‡∏ä‡πà‡∏ô ‡∏ñ‡πâ‡∏≤ predict ‡∏ß‡πà‡∏≤‡∏£‡∏π‡∏õ‡∏ô‡∏µ‡πâ‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏°‡∏ß 80% ‡πÑ‡∏õ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î 100 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á ‡∏Å‡πá‡∏Ñ‡∏ß‡∏£‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏°‡∏ß‡∏à‡∏£‡∏¥‡∏á‡πÜ 80 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á üê±

‡πÇ‡∏î‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏Å‡πá‡∏ï‡∏£‡∏á‡πÑ‡∏õ‡∏ï‡∏£‡∏á‡∏°‡∏≤‡∏Ñ‡∏∑‡∏≠ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞ train regression model (‡∏ã‡∏∂‡πà‡∏á‡∏°‡∏±‡∏ô‡πÄ‡∏≠‡∏≤‡πÑ‡∏ß‡πâ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏à‡∏£‡∏¥‡∏á ‡πÇ‡∏î‡∏¢‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥!) ‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤ ‡∏°‡∏µ input ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å classification model ‡πÅ‡∏•‡πâ‡∏ß‡∏°‡∏µ output ‡πÄ‡∏õ‡πá‡∏ô predicted probability ‡πÇ‡∏î‡∏¢ training data ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô observed probability ‡∏à‡∏≤‡∏Å‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏à‡∏£‡∏¥‡∏á

‡∏ó‡∏µ‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÉ‡∏ä‡πâ regression model ‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡πá‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏ï‡πà‡∏á‡∏≤‡∏ô‡∏•‡∏∞ ‡πÄ‡∏ä‡πà‡∏ô ‡∏á‡πà‡∏≤‡∏¢‡πÜ‡πÄ‡∏•‡∏¢‡∏Å‡πá‡πÉ‡∏ä‡πâ logistic regression ‡πÇ‡∏î‡∏¢‡∏à‡∏∞‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡πà‡∏≤ ‡∏ß‡∏¥‡∏ò‡∏µ [Platt Scaling](https://en.wikipedia.org/wiki/Platt_scaling) ‡∏ã‡∏∂‡πà‡∏á‡∏á‡πà‡∏≤‡∏¢‡∏î‡∏µ ‡πÅ‡∏ï‡πà‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢‡∏Ñ‡∏∑‡∏≠‡∏°‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô [parametric model](https://en.wikipedia.org/wiki/Parametric_model) ‡πÇ‡∏î‡∏¢‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á assume ‡∏ß‡πà‡∏≤ probability curve ‡πÄ‡∏£‡∏≤‡∏°‡∏±‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤‡πÄ‡∏õ‡πá‡∏ô sigmoid function 

‡∏Å‡πá‡πÄ‡∏•‡∏¢‡∏°‡∏µ‡∏≠‡∏µ‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ ‡∏Ñ‡∏∑‡∏≠‡πÉ‡∏ä‡πâ [Isotonic Regression](https://en.wikipedia.org/wiki/Isotonic_regression) ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ fit ‡∏Å‡∏±‡∏ö probabilty curve ‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏Å‡∏ß‡πà‡∏≤ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≠‡∏¢‡πÜ‡∏Å‡πá train ‡πÑ‡∏î‡πâ ‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ó‡πà‡∏Å‡πá‡∏Ñ‡∏∑‡∏≠ ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏°‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô monotonic function ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô ranking ‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏±‡∏á calibrate ‡∏à‡∏∞‡∏¢‡∏±‡∏á‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏™‡∏°‡∏≠! ‡πÄ‡∏ä‡πà‡∏ô ‡∏ñ‡πâ‡∏≤‡∏Å‡πà‡∏≠‡∏ô calibrate ‡πÄ‡∏£‡∏≤ predict ‡∏ß‡πà‡∏≤‡∏£‡∏π‡∏õ A ‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏°‡∏ß‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ ‡∏£‡∏π‡∏õ B ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å calibrate ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏¢‡∏±‡∏á‡∏Ñ‡∏á predict ‡∏ß‡πà‡∏≤‡∏£‡∏π‡∏õ A ‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏°‡∏ß‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ ‡∏£‡∏π‡∏õ B ‡πÅ‡∏Ñ‡πà‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏õ ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏á‡∏≤‡∏°‡∏°‡∏≤‡∏Å‡πÜ‡πÉ‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡πÜ application

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.svm import SVC
from sklearn.calibration import CalibratedClassifierCV, calibration_curve
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.isotonic import IsotonicRegression

# 1. Generate synthetic dataset
X, y = make_classification(n_samples=1000, n_features=5, random_state=42)

# 2. Split the dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. Train SVM model without calibration
svm = SVC(kernel='linear', probability=True)  # `probability=True` is required for Platt Scaling
svm.fit(X_train, y_train)

# 4. Apply Platt Scaling using CalibratedClassifierCV
calibrated_svm_platt = CalibratedClassifierCV(svm, method='sigmoid')
calibrated_svm_platt.fit(X_train, y_train)

# 5. Apply Isotonic Regression for calibration
probs_svm = svm.predict_proba(X_test)[:, 1]  # Raw probabilities from SVM model

iso_reg = IsotonicRegression(out_of_bounds='clip')
probs_isotonic = iso_reg.fit_transform(probs_svm, y_test)  # Fit isotonic regression

# 6. Get calibrated probabilities for Platt Scaling
probs_platt = calibrated_svm_platt.predict_proba(X_test)[:, 1]  # Calibrated probabilities with Platt Scaling

# 7. Compute the calibration curve for all models
true_probs_svm, predicted_probs_svm = calibration_curve(y_test, probs_svm, n_bins=10)
true_probs_platt, predicted_probs_platt = calibration_curve(y_test, probs_platt, n_bins=10)
true_probs_isotonic, predicted_probs_isotonic = calibration_curve(y_test, probs_isotonic, n_bins=10)

# 8. Plot the calibration curves
plt.figure(figsize=(8, 6))
plt.plot(predicted_probs_svm, true_probs_svm, marker='o', label="SVM (Raw Probabilities)", color='blue')
plt.plot(predicted_probs_platt, true_probs_platt, marker='s', label="SVM (Platt Scaling)", color='red')
plt.plot(predicted_probs_isotonic, true_probs_isotonic, marker='^', label="SVM (Isotonic Regression)", color='green')
plt.plot([0, 1], [0, 1], linestyle="--", label="Perfect Calibration", color='black')
plt.xlabel("Predicted Probability")
plt.ylabel("True Probability")
plt.title("Calibration Curve: SVM vs Platt Scaling vs Isotonic Regression")
plt.legend()
plt.grid(True)
plt.show()
```
